{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "z=torch.FloatTensor([1,2,3])\n",
    "y_hat=F.softmax(z,dim=0)\n",
    "print(y_hat)\n",
    "print(y_hat.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5905, 0.4853, 0.2014, 0.0306, 0.4401],\n",
      "        [0.6628, 0.7576, 0.7691, 0.2571, 0.3366],\n",
      "        [0.2386, 0.3183, 0.1332, 0.3206, 0.8843]], requires_grad=True)\n",
      "tensor([[0.2494, 0.2245, 0.1690, 0.1425, 0.2146],\n",
      "        [0.2174, 0.2390, 0.2418, 0.1449, 0.1569],\n",
      "        [0.1673, 0.1812, 0.1506, 0.1816, 0.3192]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1., 1., 1.], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z=torch.rand(3,5,requires_grad=True)\n",
    "print(z)\n",
    "y_hat=F.softmax(z,dim=1)\n",
    "print(y_hat)\n",
    "print(y_hat.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 1])\n",
      "tensor([[0.2494, 0.2245, 0.1690, 0.1425, 0.2146],\n",
      "        [0.2174, 0.2390, 0.2418, 0.1449, 0.1569],\n",
      "        [0.1673, 0.1812, 0.1506, 0.1816, 0.3192]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[3],\n",
      "        [3],\n",
      "        [1]])\n",
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.randint(5,(3,)).long()\n",
    "print(y)\n",
    "print(y_hat)\n",
    "y_one_hot=torch.zeros_like(y_hat)\n",
    "print(y_one_hot)\n",
    "print(y.unsqueeze(1))\n",
    "y_one_hot.scatter_(1,y.unsqueeze(1),1)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "x_data=[[1,2,1,1],\n",
    "        [2,1,3,2],\n",
    "        [3,1,3,4],\n",
    "        [4,1,5,5],\n",
    "        [1,7,5,5],\n",
    "        [1,2,5,6],\n",
    "        [1,6,6,6],\n",
    "        [1,7,7,7]]\n",
    "y_data=[2,2,2,1,1,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "x_train=torch.FloatTensor(x_data)\n",
    "y_train=torch.LongTensor(y_data)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y_one_hot=torch.zeros(8,3)\n",
    "print(y_one_hot)\n",
    "y_one_hot.scatter_(1,y_train.unsqueeze(1),1)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], requires_grad=True)\n",
      "tensor([[0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w=torch.zeros((4,3),requires_grad=True)\n",
    "b=torch.zeros((1,3),requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([w,b],lr=0.1)\n",
    "epochs=10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0986123085021973\n",
      "100 0.7041994333267212\n",
      "200 0.6229995489120483\n",
      "300 0.5657169222831726\n",
      "400 0.515291154384613\n",
      "500 0.46766161918640137\n",
      "600 0.42127782106399536\n",
      "700 0.3754016160964966\n",
      "800 0.3297656774520874\n",
      "900 0.2850725054740906\n",
      "1000 0.24815456569194794\n",
      "1100 0.2326759546995163\n",
      "1200 0.22139865159988403\n",
      "1300 0.2111290842294693\n",
      "1400 0.2017364799976349\n",
      "1500 0.1931132972240448\n",
      "1600 0.18516956269741058\n",
      "1700 0.17782922089099884\n",
      "1800 0.17102716863155365\n",
      "1900 0.16470736265182495\n",
      "2000 0.15882113575935364\n",
      "2100 0.15332652628421783\n",
      "2200 0.14818628132343292\n",
      "2300 0.14336803555488586\n",
      "2400 0.1388428658246994\n",
      "2500 0.13458551466464996\n",
      "2600 0.13057351112365723\n",
      "2700 0.126786470413208\n",
      "2800 0.12320646643638611\n",
      "2900 0.11981712281703949\n",
      "3000 0.11660405248403549\n",
      "3100 0.1135539561510086\n",
      "3200 0.11065515130758286\n",
      "3300 0.10789669305086136\n",
      "3400 0.10526889562606812\n",
      "3500 0.10276281088590622\n",
      "3600 0.10037028789520264\n",
      "3700 0.09808402508497238\n",
      "3800 0.09589695185422897\n",
      "3900 0.0938030257821083\n",
      "4000 0.09179661422967911\n",
      "4100 0.08987222611904144\n",
      "4200 0.08802501112222672\n",
      "4300 0.08625071495771408\n",
      "4400 0.08454487472772598\n",
      "4500 0.08290380239486694\n",
      "4600 0.08132390677928925\n",
      "4700 0.07980184257030487\n",
      "4800 0.07833462953567505\n",
      "4900 0.07691927999258041\n",
      "5000 0.07555321604013443\n",
      "5100 0.07423389703035355\n",
      "5200 0.07295893132686615\n",
      "5300 0.07172626256942749\n",
      "5400 0.07053370028734207\n",
      "5500 0.06937959045171738\n",
      "5600 0.06826187670230865\n",
      "5700 0.06717895716428757\n",
      "5800 0.06612925231456757\n",
      "5900 0.06511138379573822\n",
      "6000 0.0641237273812294\n",
      "6100 0.06316518783569336\n",
      "6200 0.06223442405462265\n",
      "6300 0.06133013591170311\n",
      "6400 0.06045139208436012\n",
      "6500 0.05959708243608475\n",
      "6600 0.05876615270972252\n",
      "6700 0.05795776844024658\n",
      "6800 0.05717097967863083\n",
      "6900 0.0564049668610096\n",
      "7000 0.05565882846713066\n",
      "7100 0.05493195354938507\n",
      "7200 0.05422358214855194\n",
      "7300 0.05353289097547531\n",
      "7400 0.052859313786029816\n",
      "7500 0.05220232531428337\n",
      "7600 0.0515611357986927\n",
      "7700 0.050935305655002594\n",
      "7800 0.05032435059547424\n",
      "7900 0.0497276596724987\n",
      "8000 0.04914472624659538\n",
      "8100 0.048575133085250854\n",
      "8200 0.0480184443295002\n",
      "8300 0.04747417941689491\n",
      "8400 0.04694199562072754\n",
      "8500 0.046421341598033905\n",
      "8600 0.04591202363371849\n",
      "8700 0.04541371762752533\n",
      "8800 0.04492587223649025\n",
      "8900 0.044448286294937134\n",
      "9000 0.043980665504932404\n",
      "9100 0.04352264478802681\n",
      "9200 0.043073952198028564\n",
      "9300 0.04263431578874588\n",
      "9400 0.04220344126224518\n",
      "9500 0.04178112745285034\n",
      "9600 0.04136704280972481\n",
      "9700 0.04096098989248276\n",
      "9800 0.04056272283196449\n",
      "9900 0.04017208144068718\n",
      "10000 0.03978879004716873\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  y_hat=F.softmax(x_train.matmul(w)+b, dim=1)\n",
    "  cost=(y_one_hot*-torch.log(y_hat)).sum(dim=1).mean()\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch%100==0:\n",
    "    print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.9508e-11, 6.5691e-06, 9.9999e-01],\n",
      "        [1.7810e-04, 1.9474e-02, 9.8035e-01],\n",
      "        [1.1670e-13, 4.1809e-02, 9.5819e-01],\n",
      "        [6.1377e-10, 9.6248e-01, 3.7520e-02],\n",
      "        [7.2622e-02, 9.2453e-01, 2.8516e-03],\n",
      "        [3.8537e-02, 9.6146e-01, 7.0806e-08],\n",
      "        [9.1229e-01, 8.7705e-02, 8.1009e-08],\n",
      "        [9.9212e-01, 7.8798e-03, 5.7660e-11]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y_hat=F.softmax(x_train.matmul(w)+b,dim=1)\n",
    "print(y_hat)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for y in y_hat:\n",
    "  print(y.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "iris=datasets.load_iris()\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4])\n",
      "torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "x_train=torch.FloatTensor(iris.data)\n",
    "y_train=torch.LongTensor(iris.target)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.8 ('pytorchtest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e473da0440022a3b9533296b86af0c6bf3963b38d184c0e31ca2ce5e4d2e295"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
