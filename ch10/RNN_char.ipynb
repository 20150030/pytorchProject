{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn실습1\n",
    "#단어를 순차적으로 나열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'apple!' : input_data => apple, output_data=pple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', 'a', 'e', 'l', 'p']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_str='apple'\n",
    "label_str='pple!'\n",
    "char_set=sorted(list(set(input_str+label_str)))\n",
    "print(char_set)\n",
    "char_set_size=len(char_set)\n",
    "print(char_set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t1.\tinput_str + label_str:\n",
    "\t•\t두 문자열을 합쳐 \"applepple!\"을 만듭니다.\n",
    "\t2.\tset():\n",
    "\t•\t합쳐진 문자열에서 중복된 문자를 제거하여 고유 문자 집합을 만듭니다.\n",
    "\t•\t결과: {'a', 'p', 'l', 'e', '!'}\n",
    "\t3.\tlist():\n",
    "\t•\t집합을 리스트로 변환합니다.\n",
    "\t•\t결과: ['a', 'p', 'l', 'e', '!'] (순서는 집합의 특성상 보장되지 않음).\n",
    "\t4.\tsorted():\n",
    "\t•\t리스트를 알파벳 순서로 정렬합니다.\n",
    "\t•\t결과: ['!', 'a', 'e', 'l', 'p']\n",
    "\t5.\tprint(char_set):\n",
    "\t•\t결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 만들기 위해 필요한 정보들\n",
    "#input과output은 정해짐\n",
    "input_size=5\n",
    "#은닉(기준이 없으니 임의로)\n",
    "hidden_size=5\n",
    "output_size=5\n",
    "learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
     ]
    }
   ],
   "source": [
    "#문자 그대로를 훈련이 아닌 벡터값을 훈련\n",
    "#c=키,i=값,enumerate=char순서의 인덱스 i와 char_set을 c에 동시에 넣음\n",
    "#[('!', 0), ('a', 1), ('e', 2), ('l', 3), ('p', 4)]\n",
    "#char_to_index=문자를 숫자로 매핑하는 딕셔너리를 생성하는 코드\n",
    "char_to_index=dict((c,i)for i,c in enumerate(char_set))\n",
    "print(char_to_index)\n",
    "# char_list=[c for c in char_set]\n",
    "#원래구조\n",
    "# char_list=[]\n",
    "# for c in char_set:\n",
    "#   char_set.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "#반대로 숫자 → 문자 변환:\n",
    "#역매핑을 하는 이유:사용자가 문자를 입력하면 숫자로 새로운 텍스트를 생성->생성된 숫자 데이터를 문자로 사용자에게 반환\n",
    "\t# •\t입력: \"hello\"\n",
    "\t# •\t출력 인덱스: [7, 4, 11, 11, 14] (각각의 문자를 숫자로 표현한 결과)\n",
    "\t# •\t역매핑을 사용해 문자로 변환: \"hello\"\n",
    "index_to_char={}\n",
    "for key, value in char_to_index.items():\n",
    "  index_to_char[value]=key\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 4, 3, 2]]\n",
      "[[4, 4, 3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "x_data=[char_to_index[c] for c in input_str]#apple\n",
    "y_data=[char_to_index[c] for c in label_str]#pple!\n",
    "#차원을 높여!\n",
    "x_data=[x_data]\n",
    "y_data=[y_data]\n",
    "\n",
    "print(x_data)\n",
    "print(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "#원핫인코딩\n",
    "#딥러닝 모델은 문자나 범주 데이터를 이해하지 못하고, 숫자 데이터만 처리할 수 있습니다. \n",
    "#문자를 숫자로 변환하는 과정이 필요 원-핫 인코딩은 범주형 데이터를 숫자로 표현하면서 데이터 간의 관계를 만들지 않도록 하기 위해 사용\n",
    "x_one_hot=[np.eye(char_set_size)[x] for x in x_data]\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 → [0., 1., 0., 0., 0.] (‘a’)\n",
    "4 → [0., 0., 0., 0., 1.] (‘p’)\n",
    "4 → [0., 0., 0., 0., 1.] (‘p’)\n",
    "3 → [0., 0., 0., 1., 0.] (‘l’)\n",
    "2 → [0., 0., 1., 0., 0.] (‘e’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "tensor([[4, 4, 3, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 원-핫 인코딩된 입력 데이터 x_one_hot을 FloatTensor로 변환\n",
    "# FloatTensor: 실수형 텐서\n",
    "X = torch.FloatTensor(x_one_hot)\n",
    "\n",
    "# 출력 데이터 y_data를 LongTensor로 변환\n",
    "# LongTensor: 정수형 텐서 (모델이 정답 레이블로 사용)\n",
    "Y = torch.LongTensor(y_data)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.RNN(input_size,hidden_size,output_size)\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size,output_size) :\n",
    "    super(Net,self).__init__()\n",
    "    self.RNN = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "    #batch_first : 입력데이터의 배치의 차원\n",
    "    #(배치크기,시퀀스길이,특징 수)\n",
    "    #입력할때 (32,10,50)이 되면 batch_first를 true로 했기 때문에 배치의 크기는 32,시퀀스길이:10,특징 수:50\n",
    "    self.fc=nn.Linear(hidden_size,output_size,bias=True)\n",
    "  #실제 구현\n",
    "  def forward(self,x):\n",
    "    x,_status=self.RNN(x)\n",
    "    x=self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t•\t문장: \"I love AI\"\n",
    "\t•\t단어 집합: ['I', 'love', 'AI']\n",
    "\t•\t입력 데이터:[\n",
    "  [1, 0, 0],  # \"I\"\n",
    "  [0, 1, 0],  # \"love\"\n",
    "  [0, 0, 1],  # \"AI\"\n",
    "]\n",
    "  •\t배치 크기 = 1 (문장이 하나만 입력됨)\n",
    "\t•\t시퀀스 길이 = 3 (문장이 3개의 단어로 구성)\n",
    "\t•\t특징 수 = 3 (단어를 3차원 원-핫 벡터로 표현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델\n",
    "model=Net(input_size,hidden_size,output_size)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0713, -0.2969, -0.2880, -0.2293,  0.3663],\n",
      "         [ 0.1286, -0.2932, -0.0973, -0.1547,  0.1787],\n",
      "         [ 0.0791, -0.0493, -0.2580, -0.2127,  0.3308],\n",
      "         [-0.2663,  0.1718, -0.6839, -0.1815,  0.7529],\n",
      "         [ 0.1142, -0.3721, -0.2642, -0.3323,  0.3330]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "output=model(X)\n",
    "print(output)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "#위 결과에서 가장 큰 인덱스\n",
    "result=output.data.numpy().argmax(axis=-1)\n",
    "#squeeze=크기가 1인 차원을 제거 \n",
    "print(np.squeeze(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 0.00028130909777246416 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "1 loss: 0.0002803319366648793 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "2 loss: 0.00027935474645346403 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "3 loss: 0.00027837755624204874 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "4 loss: 0.00027735266485251486 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "5 loss: 0.00027637547464109957 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "6 loss: 0.0002753982844296843 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "7 loss: 0.00027446873718872666 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "8 loss: 0.00027349154697731137 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "9 loss: 0.0002725382219068706 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "10 loss: 0.00027160864556208253 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "11 loss: 0.0002706552913878113 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "12 loss: 0.0002697496092878282 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "13 loss: 0.0002688200620468706 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "14 loss: 0.00026784284273162484 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "15 loss: 0.0002669132954906672 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "16 loss: 0.00026595997042022645 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "17 loss: 0.0002651019021868706 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "18 loss: 0.0002641723840497434 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "19 loss: 0.00026326667284592986 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "20 loss: 0.0002623609616421163 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "21 loss: 0.0002614075783640146 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "22 loss: 0.0002605495392344892 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "23 loss: 0.00025966769317165017 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "24 loss: 0.0002587858180049807 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "25 loss: 0.000257832434726879 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "26 loss: 0.0002569743955973536 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "27 loss: 0.00025606868439354 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "28 loss: 0.0002552106452640146 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "29 loss: 0.00025440024910494685 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "30 loss: 0.0002534945379011333 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "31 loss: 0.0002526603057049215 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "32 loss: 0.0002518261026125401 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "33 loss: 0.00025094422744587064 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "34 loss: 0.00025013386039063334 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "35 loss: 0.00024925198522396386 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "36 loss: 0.0002484177821315825 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "37 loss: 0.00024755968479439616 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "38 loss: 0.0002467254817020148 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "39 loss: 0.0002458674425724894 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "40 loss: 0.00024508085334673524 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "41 loss: 0.0002442466502543539 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "42 loss: 0.0002434362831991166 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "43 loss: 0.00024262590159196407 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "44 loss: 0.00024179168394766748 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "45 loss: 0.00024100513837765902 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "46 loss: 0.0002402424142928794 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "47 loss: 0.00023940819664858282 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "48 loss: 0.0002385978150414303 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "49 loss: 0.00023781124036759138 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "50 loss: 0.00023700084420852363 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "51 loss: 0.0002361904626013711 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "52 loss: 0.00023545157455373555 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "53 loss: 0.0002346888359170407 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "54 loss: 0.00023390229034703225 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "55 loss: 0.00023313956626225263 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "56 loss: 0.00023237685672938824 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "57 loss: 0.00023161413264460862 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "58 loss: 0.00023085139400791377 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "59 loss: 0.00023013632744550705 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "60 loss: 0.0002293497818754986 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "61 loss: 0.0002285870723426342 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "62 loss: 0.0002278481551911682 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "63 loss: 0.00022708546021021903 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "64 loss: 0.00022639422968495637 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "65 loss: 0.0002256314764963463 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "66 loss: 0.00022489258844871074 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "67 loss: 0.00022420135792344809 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "68 loss: 0.00022346246987581253 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "69 loss: 0.00022274741786532104 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "70 loss: 0.00022198466467671096 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "71 loss: 0.0002212696272181347 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "72 loss: 0.00022060221817810088 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "73 loss: 0.0002198871661676094 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "74 loss: 0.00021917207050137222 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "75 loss: 0.00021850471966899931 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "76 loss: 0.00021778963855467737 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "77 loss: 0.00021709842258132994 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "78 loss: 0.00021640716295223683 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "79 loss: 0.00021573978301603347 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "80 loss: 0.00021500085131265223 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "81 loss: 0.00021433345682453364 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "82 loss: 0.00021366607688833028 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "83 loss: 0.00021295101032592356 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "84 loss: 0.00021230746642686427 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "85 loss: 0.00021161620679777116 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "86 loss: 0.00021097266289871186 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "87 loss: 0.00021030525385867804 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "88 loss: 0.00020963784481864423 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "89 loss: 0.00020901812240481377 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "90 loss: 0.0002083030267385766 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "91 loss: 0.0002077071403618902 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "92 loss: 0.00020703976042568684 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "93 loss: 0.00020642003801185638 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "94 loss: 0.00020568110630847514 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "95 loss: 0.00020510904141701758 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "96 loss: 0.00020444163237698376 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "97 loss: 0.00020384574600029737 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "98 loss: 0.00020317833696026355 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "99 loss: 0.0002025347639573738 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "100 loss: 0.00020189120550639927 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "101 loss: 0.00020131914061494172 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "102 loss: 0.00020069940364919603 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "103 loss: 0.0002000558451982215 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "104 loss: 0.00019945992971770465 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "105 loss: 0.0001988878648262471 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "106 loss: 0.00019824430637527257 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "107 loss: 0.0001976007188204676 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "108 loss: 0.0001969809818547219 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "109 loss: 0.00019645658903755248 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "110 loss: 0.00019581301603466272 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "111 loss: 0.0001952171151060611 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "112 loss: 0.00019462118507362902 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "113 loss: 0.00019404912018217146 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "114 loss: 0.00019342938321642578 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "115 loss: 0.00019288118346594274 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "116 loss: 0.0001922614173963666 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "117 loss: 0.00019166551646776497 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "118 loss: 0.00019114112365059555 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "119 loss: 0.000190569058759138 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "120 loss: 0.00018997314327862114 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "121 loss: 0.00018937725690193474 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "122 loss: 0.0001888051483547315 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "123 loss: 0.0001882092619780451 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "124 loss: 0.00018768486916087568 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "125 loss: 0.00018713662575464696 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "126 loss: 0.00018658839690033346 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "127 loss: 0.00018604015349410474 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "128 loss: 0.00018546807405073196 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "129 loss: 0.0001848960091592744 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "130 loss: 0.00018434776575304568 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "131 loss: 0.00018379953689873219 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "132 loss: 0.00018325129349250346 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "133 loss: 0.00018275072216056287 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "134 loss: 0.00018222632934339345 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "135 loss: 0.00018167810048907995 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "136 loss: 0.00018110600649379194 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "137 loss: 0.00018058158457279205 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "138 loss: 0.00018005722085945308 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "139 loss: 0.00017950896290130913 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "140 loss: 0.0001790322276065126 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "141 loss: 0.00017848398420028389 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "142 loss: 0.0001779834128683433 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "143 loss: 0.0001774351840140298 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "144 loss: 0.00017691076209302992 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "145 loss: 0.00017641020531300455 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "146 loss: 0.00017586196190677583 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "147 loss: 0.00017536137602292 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "148 loss: 0.00017488465528003871 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "149 loss: 0.00017436023335903883 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "150 loss: 0.00017383585509378463 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "151 loss: 0.0001733352692099288 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "152 loss: 0.00017283469787798822 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "153 loss: 0.00017233412654604763 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "154 loss: 0.0001718573912512511 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "155 loss: 0.0001713806705083698 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "156 loss: 0.00017090390610974282 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "157 loss: 0.00017042718536686152 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "158 loss: 0.00016990277799777687 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "159 loss: 0.00016944986418820918 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "160 loss: 0.00016890163533389568 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "161 loss: 0.00016844870697241277 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "162 loss: 0.00016797197167761624 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "163 loss: 0.00016749525093473494 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "164 loss: 0.00016701848653610796 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "165 loss: 0.0001665417803451419 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "166 loss: 0.00016601737297605723 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "167 loss: 0.00016558830975554883 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "168 loss: 0.00016506388783454895 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "169 loss: 0.00016465866065118462 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "170 loss: 0.00016418191080447286 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "171 loss: 0.00016370517550967634 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "172 loss: 0.00016327611228916794 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "173 loss: 0.00016282321303151548 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "174 loss: 0.0001623702992219478 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "175 loss: 0.00016191739996429533 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "176 loss: 0.00016146448615472764 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "177 loss: 0.00016101158689707518 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "178 loss: 0.00016055868763942271 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "179 loss: 0.00016010577382985502 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "180 loss: 0.00015970053209457546 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "181 loss: 0.000159247632836923 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "182 loss: 0.00015881858416832983 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "183 loss: 0.0001583418488735333 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "184 loss: 0.00015786508447490633 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "185 loss: 0.00015745984273962677 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "186 loss: 0.0001570069434819743 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "187 loss: 0.0001565778802614659 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "188 loss: 0.0001561488170409575 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "189 loss: 0.00015571973926853389 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "190 loss: 0.00015531449753325433 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "191 loss: 0.00015486158372368664 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "192 loss: 0.00015448019257746637 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "193 loss: 0.00015405112935695797 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "194 loss: 0.00015362205158453435 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "195 loss: 0.00015321682440117002 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "196 loss: 0.00015281158266589046 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "197 loss: 0.00015235866885632277 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "198 loss: 0.0001519772777101025 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n",
      "199 loss: 0.00015157203597482294 prediction: [[4 4 3 2 0]] pple! true: [[4, 4, 3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "  optimizer.zero_grad()\n",
    "  output=model(X)\n",
    "  loss=criterion(output.view(-1,input_size),Y.view(-1))\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  result=output.data.numpy().argmax(axis=-1)\n",
    "  str_result=''.join([index_to_char[c] for c in np.squeeze(result)])\n",
    "  print(i,\"loss:\",loss.item(),\"prediction:\",result,str_result,'true:',y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#여러줄\n",
    "sentence = \"\"\"For the past 11 years, Straus has been House chair of the joint Transportation Committee. \n",
    "He also sits on a transportation funding task force charged with considering \n",
    "what the next era of transportation funding could look like as the notoriously \n",
    "under-resourced MBTA barrels toward a fiscal cliff.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', ' ', 'M', 'a', 'y', 'e', 'B', 'C', 'x', 'd', ',', 'k', '.', 'w', 'o', 'b', 'S', 'i', 'm', '\\n', 'g', 'p', '1', 'h', 'c', 'l', 'r', 'u', 'T', 'f', 'F', 'n', 'j', '-', 'A', 's', 'H']\n"
     ]
    }
   ],
   "source": [
    "#문자셋으로 만들기\n",
    "#중복제거\n",
    "char_set2=list(set(sentence))\n",
    "print(char_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': 0,\n",
       " ' ': 1,\n",
       " 'M': 2,\n",
       " 'a': 3,\n",
       " 'y': 4,\n",
       " 'e': 5,\n",
       " 'B': 6,\n",
       " 'C': 7,\n",
       " 'x': 8,\n",
       " 'd': 9,\n",
       " ',': 10,\n",
       " 'k': 11,\n",
       " '.': 12,\n",
       " 'w': 13,\n",
       " 'o': 14,\n",
       " 'b': 15,\n",
       " 'S': 16,\n",
       " 'i': 17,\n",
       " 'm': 18,\n",
       " '\\n': 19,\n",
       " 'g': 20,\n",
       " 'p': 21,\n",
       " '1': 22,\n",
       " 'h': 23,\n",
       " 'c': 24,\n",
       " 'l': 25,\n",
       " 'r': 26,\n",
       " 'u': 27,\n",
       " 'T': 28,\n",
       " 'f': 29,\n",
       " 'F': 30,\n",
       " 'n': 31,\n",
       " 'j': 32,\n",
       " '-': 33,\n",
       " 'A': 34,\n",
       " 's': 35,\n",
       " 'H': 36}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dic={c:i for i,c in enumerate(char_set2)}\n",
    "char_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "#크기구하기\n",
    "char_dic_size=len(char_dic)\n",
    "print(char_dic_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=char_dic_size\n",
    "#sequence_length:세트를 나눔 글자 10개씩 한세트를 만들어 훈련을 하겠다!\n",
    "sequence_length=10\n",
    "learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 For the pa : or the pa\n",
      "1 or the pas : r the pas\n",
      "2 r the past :  the past\n",
      "3  the past  : the past \n",
      "4 the past 1 : he past 1\n",
      "5 he past 11 : e past 11\n",
      "6 e past 11  :  past 11 \n",
      "7  past 11 y : past 11 y\n",
      "8 past 11 ye : ast 11 ye\n",
      "9 ast 11 yea : st 11 yea\n",
      "10 st 11 year : t 11 year\n",
      "11 t 11 years :  11 years\n",
      "12  11 years, : 11 years,\n",
      "13 11 years,  : 1 years, \n",
      "14 1 years, S :  years, S\n",
      "15  years, St : years, St\n",
      "16 years, Str : ears, Str\n",
      "17 ears, Stra : ars, Stra\n",
      "18 ars, Strau : rs, Strau\n",
      "19 rs, Straus : s, Straus\n",
      "20 s, Straus  : , Straus \n",
      "21 , Straus h :  Straus h\n",
      "22  Straus ha : Straus ha\n",
      "23 Straus has : traus has\n",
      "24 traus has  : raus has \n",
      "25 raus has b : aus has b\n",
      "26 aus has be : us has be\n",
      "27 us has bee : s has bee\n",
      "28 s has been :  has been\n",
      "29  has been  : has been \n",
      "30 has been H : as been H\n",
      "31 as been Ho : s been Ho\n",
      "32 s been Hou :  been Hou\n",
      "33  been Hous : been Hous\n",
      "34 been House : een House\n",
      "35 een House  : en House \n",
      "36 en House c : n House c\n",
      "37 n House ch :  House ch\n",
      "38  House cha : House cha\n",
      "39 House chai : ouse chai\n",
      "40 ouse chair : use chair\n",
      "41 use chair  : se chair \n",
      "42 se chair o : e chair o\n",
      "43 e chair of :  chair of\n",
      "44  chair of  : chair of \n",
      "45 chair of t : hair of t\n",
      "46 hair of th : air of th\n",
      "47 air of the : ir of the\n",
      "48 ir of the  : r of the \n",
      "49 r of the j :  of the j\n",
      "50  of the jo : of the jo\n",
      "51 of the joi : f the joi\n",
      "52 f the join :  the join\n",
      "53  the joint : the joint\n",
      "54 the joint  : he joint \n",
      "55 he joint T : e joint T\n",
      "56 e joint Tr :  joint Tr\n",
      "57  joint Tra : joint Tra\n",
      "58 joint Tran : oint Tran\n",
      "59 oint Trans : int Trans\n",
      "60 int Transp : nt Transp\n",
      "61 nt Transpo : t Transpo\n",
      "62 t Transpor :  Transpor\n",
      "63  Transport : Transport\n",
      "64 Transporta : ransporta\n",
      "65 ransportat : ansportat\n",
      "66 ansportati : nsportati\n",
      "67 nsportatio : sportatio\n",
      "68 sportation : portation\n",
      "69 portation  : ortation \n",
      "70 ortation C : rtation C\n",
      "71 rtation Co : tation Co\n",
      "72 tation Com : ation Com\n",
      "73 ation Comm : tion Comm\n",
      "74 tion Commi : ion Commi\n",
      "75 ion Commit : on Commit\n",
      "76 on Committ : n Committ\n",
      "77 n Committe :  Committe\n",
      "78  Committee : Committee\n",
      "79 Committee. : ommittee.\n",
      "80 ommittee.  : mmittee. \n",
      "81 mmittee. \n",
      " : mittee. \n",
      "\n",
      "82 mittee. \n",
      "H : ittee. \n",
      "H\n",
      "83 ittee. \n",
      "He : ttee. \n",
      "He\n",
      "84 ttee. \n",
      "He  : tee. \n",
      "He \n",
      "85 tee. \n",
      "He a : ee. \n",
      "He a\n",
      "86 ee. \n",
      "He al : e. \n",
      "He al\n",
      "87 e. \n",
      "He als : . \n",
      "He als\n",
      "88 . \n",
      "He also :  \n",
      "He also\n",
      "89  \n",
      "He also  : \n",
      "He also \n",
      "90 \n",
      "He also s : He also s\n",
      "91 He also si : e also si\n",
      "92 e also sit :  also sit\n",
      "93  also sits : also sits\n",
      "94 also sits  : lso sits \n",
      "95 lso sits o : so sits o\n",
      "96 so sits on : o sits on\n",
      "97 o sits on  :  sits on \n",
      "98  sits on a : sits on a\n",
      "99 sits on a  : its on a \n",
      "100 its on a t : ts on a t\n",
      "101 ts on a tr : s on a tr\n",
      "102 s on a tra :  on a tra\n",
      "103  on a tran : on a tran\n",
      "104 on a trans : n a trans\n",
      "105 n a transp :  a transp\n",
      "106  a transpo : a transpo\n",
      "107 a transpor :  transpor\n",
      "108  transport : transport\n",
      "109 transporta : ransporta\n",
      "110 ransportat : ansportat\n",
      "111 ansportati : nsportati\n",
      "112 nsportatio : sportatio\n",
      "113 sportation : portation\n",
      "114 portation  : ortation \n",
      "115 ortation f : rtation f\n",
      "116 rtation fu : tation fu\n",
      "117 tation fun : ation fun\n",
      "118 ation fund : tion fund\n",
      "119 tion fundi : ion fundi\n",
      "120 ion fundin : on fundin\n",
      "121 on funding : n funding\n",
      "122 n funding  :  funding \n",
      "123  funding t : funding t\n",
      "124 funding ta : unding ta\n",
      "125 unding tas : nding tas\n",
      "126 nding task : ding task\n",
      "127 ding task  : ing task \n",
      "128 ing task f : ng task f\n",
      "129 ng task fo : g task fo\n",
      "130 g task for :  task for\n",
      "131  task forc : task forc\n",
      "132 task force : ask force\n",
      "133 ask force  : sk force \n",
      "134 sk force c : k force c\n",
      "135 k force ch :  force ch\n",
      "136  force cha : force cha\n",
      "137 force char : orce char\n",
      "138 orce charg : rce charg\n",
      "139 rce charge : ce charge\n",
      "140 ce charged : e charged\n",
      "141 e charged  :  charged \n",
      "142  charged w : charged w\n",
      "143 charged wi : harged wi\n",
      "144 harged wit : arged wit\n",
      "145 arged with : rged with\n",
      "146 rged with  : ged with \n",
      "147 ged with c : ed with c\n",
      "148 ed with co : d with co\n",
      "149 d with con :  with con\n",
      "150  with cons : with cons\n",
      "151 with consi : ith consi\n",
      "152 ith consid : th consid\n",
      "153 th conside : h conside\n",
      "154 h consider :  consider\n",
      "155  consideri : consideri\n",
      "156 considerin : onsiderin\n",
      "157 onsidering : nsidering\n",
      "158 nsidering  : sidering \n",
      "159 sidering \n",
      " : idering \n",
      "\n",
      "160 idering \n",
      "w : dering \n",
      "w\n",
      "161 dering \n",
      "wh : ering \n",
      "wh\n",
      "162 ering \n",
      "wha : ring \n",
      "wha\n",
      "163 ring \n",
      "what : ing \n",
      "what\n",
      "164 ing \n",
      "what  : ng \n",
      "what \n",
      "165 ng \n",
      "what t : g \n",
      "what t\n",
      "166 g \n",
      "what th :  \n",
      "what th\n",
      "167  \n",
      "what the : \n",
      "what the\n",
      "168 \n",
      "what the  : what the \n",
      "169 what the n : hat the n\n",
      "170 hat the ne : at the ne\n",
      "171 at the nex : t the nex\n",
      "172 t the next :  the next\n",
      "173  the next  : the next \n",
      "174 the next e : he next e\n",
      "175 he next er : e next er\n",
      "176 e next era :  next era\n",
      "177  next era  : next era \n",
      "178 next era o : ext era o\n",
      "179 ext era of : xt era of\n",
      "180 xt era of  : t era of \n",
      "181 t era of t :  era of t\n",
      "182  era of tr : era of tr\n",
      "183 era of tra : ra of tra\n",
      "184 ra of tran : a of tran\n",
      "185 a of trans :  of trans\n",
      "186  of transp : of transp\n",
      "187 of transpo : f transpo\n",
      "188 f transpor :  transpor\n",
      "189  transport : transport\n",
      "190 transporta : ransporta\n",
      "191 ransportat : ansportat\n",
      "192 ansportati : nsportati\n",
      "193 nsportatio : sportatio\n",
      "194 sportation : portation\n",
      "195 portation  : ortation \n",
      "196 ortation f : rtation f\n",
      "197 rtation fu : tation fu\n",
      "198 tation fun : ation fun\n",
      "199 ation fund : tion fund\n",
      "200 tion fundi : ion fundi\n",
      "201 ion fundin : on fundin\n",
      "202 on funding : n funding\n",
      "203 n funding  :  funding \n",
      "204  funding c : funding c\n",
      "205 funding co : unding co\n",
      "206 unding cou : nding cou\n",
      "207 nding coul : ding coul\n",
      "208 ding could : ing could\n",
      "209 ing could  : ng could \n",
      "210 ng could l : g could l\n",
      "211 g could lo :  could lo\n",
      "212  could loo : could loo\n",
      "213 could look : ould look\n",
      "214 ould look  : uld look \n",
      "215 uld look l : ld look l\n",
      "216 ld look li : d look li\n",
      "217 d look lik :  look lik\n",
      "218  look like : look like\n",
      "219 look like  : ook like \n",
      "220 ook like a : ok like a\n",
      "221 ok like as : k like as\n",
      "222 k like as  :  like as \n",
      "223  like as t : like as t\n",
      "224 like as th : ike as th\n",
      "225 ike as the : ke as the\n",
      "226 ke as the  : e as the \n",
      "227 e as the n :  as the n\n",
      "228  as the no : as the no\n",
      "229 as the not : s the not\n",
      "230 s the noto :  the noto\n",
      "231  the notor : the notor\n",
      "232 the notori : he notori\n",
      "233 he notorio : e notorio\n",
      "234 e notoriou :  notoriou\n",
      "235  notorious : notorious\n",
      "236 notoriousl : otoriousl\n",
      "237 otoriously : toriously\n",
      "238 toriously  : oriously \n",
      "239 oriously \n",
      " : riously \n",
      "\n",
      "240 riously \n",
      "u : iously \n",
      "u\n",
      "241 iously \n",
      "un : ously \n",
      "un\n",
      "242 ously \n",
      "und : usly \n",
      "und\n",
      "243 usly \n",
      "unde : sly \n",
      "unde\n",
      "244 sly \n",
      "under : ly \n",
      "under\n",
      "245 ly \n",
      "under- : y \n",
      "under-\n",
      "246 y \n",
      "under-r :  \n",
      "under-r\n",
      "247  \n",
      "under-re : \n",
      "under-re\n",
      "248 \n",
      "under-res : under-res\n",
      "249 under-reso : nder-reso\n",
      "250 nder-resou : der-resou\n",
      "251 der-resour : er-resour\n",
      "252 er-resourc : r-resourc\n",
      "253 r-resource : -resource\n",
      "254 -resourced : resourced\n",
      "255 resourced  : esourced \n",
      "256 esourced M : sourced M\n",
      "257 sourced MB : ourced MB\n",
      "258 ourced MBT : urced MBT\n",
      "259 urced MBTA : rced MBTA\n",
      "260 rced MBTA  : ced MBTA \n",
      "261 ced MBTA b : ed MBTA b\n",
      "262 ed MBTA ba : d MBTA ba\n",
      "263 d MBTA bar :  MBTA bar\n",
      "264  MBTA barr : MBTA barr\n",
      "265 MBTA barre : BTA barre\n",
      "266 BTA barrel : TA barrel\n",
      "267 TA barrels : A barrels\n",
      "268 A barrels  :  barrels \n",
      "269  barrels t : barrels t\n",
      "270 barrels to : arrels to\n",
      "271 arrels tow : rrels tow\n",
      "272 rrels towa : rels towa\n",
      "273 rels towar : els towar\n",
      "274 els toward : ls toward\n",
      "275 ls toward  : s toward \n",
      "276 s toward a :  toward a\n",
      "277  toward a  : toward a \n",
      "278 toward a f : oward a f\n",
      "279 oward a fi : ward a fi\n",
      "280 ward a fis : ard a fis\n",
      "281 ard a fisc : rd a fisc\n",
      "282 rd a fisca : d a fisca\n",
      "283 d a fiscal :  a fiscal\n",
      "284  a fiscal  : a fiscal \n",
      "285 a fiscal c :  fiscal c\n",
      "286  fiscal cl : fiscal cl\n",
      "287 fiscal cli : iscal cli\n",
      "288 iscal clif : scal clif\n",
      "289 scal cliff : cal cliff\n"
     ]
    }
   ],
   "source": [
    "x_data=[]\n",
    "y_data=[]\n",
    "\n",
    "for i in range(0,len(sentence)-sequence_length):\n",
    "  x_str=sentence[i:i+sequence_length]\n",
    "  y_str=sentence[i+1:i+sequence_length]\n",
    "  print(i,x_str,':',y_str)\n",
    "  x_data.append([char_dic[c] for c in x_str])\n",
    "  y_data.append([char_dic[c] for c in y_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 14, 26, 1, 0, 23, 5, 1, 21, 3], [14, 26, 1, 0, 23, 5, 1, 21, 3, 35], [26, 1, 0, 23, 5, 1, 21, 3, 35, 0], [1, 0, 23, 5, 1, 21, 3, 35, 0, 1], [0, 23, 5, 1, 21, 3, 35, 0, 1, 22], [23, 5, 1, 21, 3, 35, 0, 1, 22, 22], [5, 1, 21, 3, 35, 0, 1, 22, 22, 1], [1, 21, 3, 35, 0, 1, 22, 22, 1, 4], [21, 3, 35, 0, 1, 22, 22, 1, 4, 5], [3, 35, 0, 1, 22, 22, 1, 4, 5, 3], [35, 0, 1, 22, 22, 1, 4, 5, 3, 26], [0, 1, 22, 22, 1, 4, 5, 3, 26, 35], [1, 22, 22, 1, 4, 5, 3, 26, 35, 10], [22, 22, 1, 4, 5, 3, 26, 35, 10, 1], [22, 1, 4, 5, 3, 26, 35, 10, 1, 16], [1, 4, 5, 3, 26, 35, 10, 1, 16, 0], [4, 5, 3, 26, 35, 10, 1, 16, 0, 26], [5, 3, 26, 35, 10, 1, 16, 0, 26, 3], [3, 26, 35, 10, 1, 16, 0, 26, 3, 27], [26, 35, 10, 1, 16, 0, 26, 3, 27, 35], [35, 10, 1, 16, 0, 26, 3, 27, 35, 1], [10, 1, 16, 0, 26, 3, 27, 35, 1, 23], [1, 16, 0, 26, 3, 27, 35, 1, 23, 3], [16, 0, 26, 3, 27, 35, 1, 23, 3, 35], [0, 26, 3, 27, 35, 1, 23, 3, 35, 1], [26, 3, 27, 35, 1, 23, 3, 35, 1, 15], [3, 27, 35, 1, 23, 3, 35, 1, 15, 5], [27, 35, 1, 23, 3, 35, 1, 15, 5, 5], [35, 1, 23, 3, 35, 1, 15, 5, 5, 31], [1, 23, 3, 35, 1, 15, 5, 5, 31, 1], [23, 3, 35, 1, 15, 5, 5, 31, 1, 36], [3, 35, 1, 15, 5, 5, 31, 1, 36, 14], [35, 1, 15, 5, 5, 31, 1, 36, 14, 27], [1, 15, 5, 5, 31, 1, 36, 14, 27, 35], [15, 5, 5, 31, 1, 36, 14, 27, 35, 5], [5, 5, 31, 1, 36, 14, 27, 35, 5, 1], [5, 31, 1, 36, 14, 27, 35, 5, 1, 24], [31, 1, 36, 14, 27, 35, 5, 1, 24, 23], [1, 36, 14, 27, 35, 5, 1, 24, 23, 3], [36, 14, 27, 35, 5, 1, 24, 23, 3, 17], [14, 27, 35, 5, 1, 24, 23, 3, 17, 26], [27, 35, 5, 1, 24, 23, 3, 17, 26, 1], [35, 5, 1, 24, 23, 3, 17, 26, 1, 14], [5, 1, 24, 23, 3, 17, 26, 1, 14, 29], [1, 24, 23, 3, 17, 26, 1, 14, 29, 1], [24, 23, 3, 17, 26, 1, 14, 29, 1, 0], [23, 3, 17, 26, 1, 14, 29, 1, 0, 23], [3, 17, 26, 1, 14, 29, 1, 0, 23, 5], [17, 26, 1, 14, 29, 1, 0, 23, 5, 1], [26, 1, 14, 29, 1, 0, 23, 5, 1, 32], [1, 14, 29, 1, 0, 23, 5, 1, 32, 14], [14, 29, 1, 0, 23, 5, 1, 32, 14, 17], [29, 1, 0, 23, 5, 1, 32, 14, 17, 31], [1, 0, 23, 5, 1, 32, 14, 17, 31, 0], [0, 23, 5, 1, 32, 14, 17, 31, 0, 1], [23, 5, 1, 32, 14, 17, 31, 0, 1, 28], [5, 1, 32, 14, 17, 31, 0, 1, 28, 26], [1, 32, 14, 17, 31, 0, 1, 28, 26, 3], [32, 14, 17, 31, 0, 1, 28, 26, 3, 31], [14, 17, 31, 0, 1, 28, 26, 3, 31, 35], [17, 31, 0, 1, 28, 26, 3, 31, 35, 21], [31, 0, 1, 28, 26, 3, 31, 35, 21, 14], [0, 1, 28, 26, 3, 31, 35, 21, 14, 26], [1, 28, 26, 3, 31, 35, 21, 14, 26, 0], [28, 26, 3, 31, 35, 21, 14, 26, 0, 3], [26, 3, 31, 35, 21, 14, 26, 0, 3, 0], [3, 31, 35, 21, 14, 26, 0, 3, 0, 17], [31, 35, 21, 14, 26, 0, 3, 0, 17, 14], [35, 21, 14, 26, 0, 3, 0, 17, 14, 31], [21, 14, 26, 0, 3, 0, 17, 14, 31, 1], [14, 26, 0, 3, 0, 17, 14, 31, 1, 7], [26, 0, 3, 0, 17, 14, 31, 1, 7, 14], [0, 3, 0, 17, 14, 31, 1, 7, 14, 18], [3, 0, 17, 14, 31, 1, 7, 14, 18, 18], [0, 17, 14, 31, 1, 7, 14, 18, 18, 17], [17, 14, 31, 1, 7, 14, 18, 18, 17, 0], [14, 31, 1, 7, 14, 18, 18, 17, 0, 0], [31, 1, 7, 14, 18, 18, 17, 0, 0, 5], [1, 7, 14, 18, 18, 17, 0, 0, 5, 5], [7, 14, 18, 18, 17, 0, 0, 5, 5, 12], [14, 18, 18, 17, 0, 0, 5, 5, 12, 1], [18, 18, 17, 0, 0, 5, 5, 12, 1, 19], [18, 17, 0, 0, 5, 5, 12, 1, 19, 36], [17, 0, 0, 5, 5, 12, 1, 19, 36, 5], [0, 0, 5, 5, 12, 1, 19, 36, 5, 1], [0, 5, 5, 12, 1, 19, 36, 5, 1, 3], [5, 5, 12, 1, 19, 36, 5, 1, 3, 25], [5, 12, 1, 19, 36, 5, 1, 3, 25, 35], [12, 1, 19, 36, 5, 1, 3, 25, 35, 14], [1, 19, 36, 5, 1, 3, 25, 35, 14, 1], [19, 36, 5, 1, 3, 25, 35, 14, 1, 35], [36, 5, 1, 3, 25, 35, 14, 1, 35, 17], [5, 1, 3, 25, 35, 14, 1, 35, 17, 0], [1, 3, 25, 35, 14, 1, 35, 17, 0, 35], [3, 25, 35, 14, 1, 35, 17, 0, 35, 1], [25, 35, 14, 1, 35, 17, 0, 35, 1, 14], [35, 14, 1, 35, 17, 0, 35, 1, 14, 31], [14, 1, 35, 17, 0, 35, 1, 14, 31, 1], [1, 35, 17, 0, 35, 1, 14, 31, 1, 3], [35, 17, 0, 35, 1, 14, 31, 1, 3, 1], [17, 0, 35, 1, 14, 31, 1, 3, 1, 0], [0, 35, 1, 14, 31, 1, 3, 1, 0, 26], [35, 1, 14, 31, 1, 3, 1, 0, 26, 3], [1, 14, 31, 1, 3, 1, 0, 26, 3, 31], [14, 31, 1, 3, 1, 0, 26, 3, 31, 35], [31, 1, 3, 1, 0, 26, 3, 31, 35, 21], [1, 3, 1, 0, 26, 3, 31, 35, 21, 14], [3, 1, 0, 26, 3, 31, 35, 21, 14, 26], [1, 0, 26, 3, 31, 35, 21, 14, 26, 0], [0, 26, 3, 31, 35, 21, 14, 26, 0, 3], [26, 3, 31, 35, 21, 14, 26, 0, 3, 0], [3, 31, 35, 21, 14, 26, 0, 3, 0, 17], [31, 35, 21, 14, 26, 0, 3, 0, 17, 14], [35, 21, 14, 26, 0, 3, 0, 17, 14, 31], [21, 14, 26, 0, 3, 0, 17, 14, 31, 1], [14, 26, 0, 3, 0, 17, 14, 31, 1, 29], [26, 0, 3, 0, 17, 14, 31, 1, 29, 27], [0, 3, 0, 17, 14, 31, 1, 29, 27, 31], [3, 0, 17, 14, 31, 1, 29, 27, 31, 9], [0, 17, 14, 31, 1, 29, 27, 31, 9, 17], [17, 14, 31, 1, 29, 27, 31, 9, 17, 31], [14, 31, 1, 29, 27, 31, 9, 17, 31, 20], [31, 1, 29, 27, 31, 9, 17, 31, 20, 1], [1, 29, 27, 31, 9, 17, 31, 20, 1, 0], [29, 27, 31, 9, 17, 31, 20, 1, 0, 3], [27, 31, 9, 17, 31, 20, 1, 0, 3, 35], [31, 9, 17, 31, 20, 1, 0, 3, 35, 11], [9, 17, 31, 20, 1, 0, 3, 35, 11, 1], [17, 31, 20, 1, 0, 3, 35, 11, 1, 29], [31, 20, 1, 0, 3, 35, 11, 1, 29, 14], [20, 1, 0, 3, 35, 11, 1, 29, 14, 26], [1, 0, 3, 35, 11, 1, 29, 14, 26, 24], [0, 3, 35, 11, 1, 29, 14, 26, 24, 5], [3, 35, 11, 1, 29, 14, 26, 24, 5, 1], [35, 11, 1, 29, 14, 26, 24, 5, 1, 24], [11, 1, 29, 14, 26, 24, 5, 1, 24, 23], [1, 29, 14, 26, 24, 5, 1, 24, 23, 3], [29, 14, 26, 24, 5, 1, 24, 23, 3, 26], [14, 26, 24, 5, 1, 24, 23, 3, 26, 20], [26, 24, 5, 1, 24, 23, 3, 26, 20, 5], [24, 5, 1, 24, 23, 3, 26, 20, 5, 9], [5, 1, 24, 23, 3, 26, 20, 5, 9, 1], [1, 24, 23, 3, 26, 20, 5, 9, 1, 13], [24, 23, 3, 26, 20, 5, 9, 1, 13, 17], [23, 3, 26, 20, 5, 9, 1, 13, 17, 0], [3, 26, 20, 5, 9, 1, 13, 17, 0, 23], [26, 20, 5, 9, 1, 13, 17, 0, 23, 1], [20, 5, 9, 1, 13, 17, 0, 23, 1, 24], [5, 9, 1, 13, 17, 0, 23, 1, 24, 14], [9, 1, 13, 17, 0, 23, 1, 24, 14, 31], [1, 13, 17, 0, 23, 1, 24, 14, 31, 35], [13, 17, 0, 23, 1, 24, 14, 31, 35, 17], [17, 0, 23, 1, 24, 14, 31, 35, 17, 9], [0, 23, 1, 24, 14, 31, 35, 17, 9, 5], [23, 1, 24, 14, 31, 35, 17, 9, 5, 26], [1, 24, 14, 31, 35, 17, 9, 5, 26, 17], [24, 14, 31, 35, 17, 9, 5, 26, 17, 31], [14, 31, 35, 17, 9, 5, 26, 17, 31, 20], [31, 35, 17, 9, 5, 26, 17, 31, 20, 1], [35, 17, 9, 5, 26, 17, 31, 20, 1, 19], [17, 9, 5, 26, 17, 31, 20, 1, 19, 13], [9, 5, 26, 17, 31, 20, 1, 19, 13, 23], [5, 26, 17, 31, 20, 1, 19, 13, 23, 3], [26, 17, 31, 20, 1, 19, 13, 23, 3, 0], [17, 31, 20, 1, 19, 13, 23, 3, 0, 1], [31, 20, 1, 19, 13, 23, 3, 0, 1, 0], [20, 1, 19, 13, 23, 3, 0, 1, 0, 23], [1, 19, 13, 23, 3, 0, 1, 0, 23, 5], [19, 13, 23, 3, 0, 1, 0, 23, 5, 1], [13, 23, 3, 0, 1, 0, 23, 5, 1, 31], [23, 3, 0, 1, 0, 23, 5, 1, 31, 5], [3, 0, 1, 0, 23, 5, 1, 31, 5, 8], [0, 1, 0, 23, 5, 1, 31, 5, 8, 0], [1, 0, 23, 5, 1, 31, 5, 8, 0, 1], [0, 23, 5, 1, 31, 5, 8, 0, 1, 5], [23, 5, 1, 31, 5, 8, 0, 1, 5, 26], [5, 1, 31, 5, 8, 0, 1, 5, 26, 3], [1, 31, 5, 8, 0, 1, 5, 26, 3, 1], [31, 5, 8, 0, 1, 5, 26, 3, 1, 14], [5, 8, 0, 1, 5, 26, 3, 1, 14, 29], [8, 0, 1, 5, 26, 3, 1, 14, 29, 1], [0, 1, 5, 26, 3, 1, 14, 29, 1, 0], [1, 5, 26, 3, 1, 14, 29, 1, 0, 26], [5, 26, 3, 1, 14, 29, 1, 0, 26, 3], [26, 3, 1, 14, 29, 1, 0, 26, 3, 31], [3, 1, 14, 29, 1, 0, 26, 3, 31, 35], [1, 14, 29, 1, 0, 26, 3, 31, 35, 21], [14, 29, 1, 0, 26, 3, 31, 35, 21, 14], [29, 1, 0, 26, 3, 31, 35, 21, 14, 26], [1, 0, 26, 3, 31, 35, 21, 14, 26, 0], [0, 26, 3, 31, 35, 21, 14, 26, 0, 3], [26, 3, 31, 35, 21, 14, 26, 0, 3, 0], [3, 31, 35, 21, 14, 26, 0, 3, 0, 17], [31, 35, 21, 14, 26, 0, 3, 0, 17, 14], [35, 21, 14, 26, 0, 3, 0, 17, 14, 31], [21, 14, 26, 0, 3, 0, 17, 14, 31, 1], [14, 26, 0, 3, 0, 17, 14, 31, 1, 29], [26, 0, 3, 0, 17, 14, 31, 1, 29, 27], [0, 3, 0, 17, 14, 31, 1, 29, 27, 31], [3, 0, 17, 14, 31, 1, 29, 27, 31, 9], [0, 17, 14, 31, 1, 29, 27, 31, 9, 17], [17, 14, 31, 1, 29, 27, 31, 9, 17, 31], [14, 31, 1, 29, 27, 31, 9, 17, 31, 20], [31, 1, 29, 27, 31, 9, 17, 31, 20, 1], [1, 29, 27, 31, 9, 17, 31, 20, 1, 24], [29, 27, 31, 9, 17, 31, 20, 1, 24, 14], [27, 31, 9, 17, 31, 20, 1, 24, 14, 27], [31, 9, 17, 31, 20, 1, 24, 14, 27, 25], [9, 17, 31, 20, 1, 24, 14, 27, 25, 9], [17, 31, 20, 1, 24, 14, 27, 25, 9, 1], [31, 20, 1, 24, 14, 27, 25, 9, 1, 25], [20, 1, 24, 14, 27, 25, 9, 1, 25, 14], [1, 24, 14, 27, 25, 9, 1, 25, 14, 14], [24, 14, 27, 25, 9, 1, 25, 14, 14, 11], [14, 27, 25, 9, 1, 25, 14, 14, 11, 1], [27, 25, 9, 1, 25, 14, 14, 11, 1, 25], [25, 9, 1, 25, 14, 14, 11, 1, 25, 17], [9, 1, 25, 14, 14, 11, 1, 25, 17, 11], [1, 25, 14, 14, 11, 1, 25, 17, 11, 5], [25, 14, 14, 11, 1, 25, 17, 11, 5, 1], [14, 14, 11, 1, 25, 17, 11, 5, 1, 3], [14, 11, 1, 25, 17, 11, 5, 1, 3, 35], [11, 1, 25, 17, 11, 5, 1, 3, 35, 1], [1, 25, 17, 11, 5, 1, 3, 35, 1, 0], [25, 17, 11, 5, 1, 3, 35, 1, 0, 23], [17, 11, 5, 1, 3, 35, 1, 0, 23, 5], [11, 5, 1, 3, 35, 1, 0, 23, 5, 1], [5, 1, 3, 35, 1, 0, 23, 5, 1, 31], [1, 3, 35, 1, 0, 23, 5, 1, 31, 14], [3, 35, 1, 0, 23, 5, 1, 31, 14, 0], [35, 1, 0, 23, 5, 1, 31, 14, 0, 14], [1, 0, 23, 5, 1, 31, 14, 0, 14, 26], [0, 23, 5, 1, 31, 14, 0, 14, 26, 17], [23, 5, 1, 31, 14, 0, 14, 26, 17, 14], [5, 1, 31, 14, 0, 14, 26, 17, 14, 27], [1, 31, 14, 0, 14, 26, 17, 14, 27, 35], [31, 14, 0, 14, 26, 17, 14, 27, 35, 25], [14, 0, 14, 26, 17, 14, 27, 35, 25, 4], [0, 14, 26, 17, 14, 27, 35, 25, 4, 1], [14, 26, 17, 14, 27, 35, 25, 4, 1, 19], [26, 17, 14, 27, 35, 25, 4, 1, 19, 27], [17, 14, 27, 35, 25, 4, 1, 19, 27, 31], [14, 27, 35, 25, 4, 1, 19, 27, 31, 9], [27, 35, 25, 4, 1, 19, 27, 31, 9, 5], [35, 25, 4, 1, 19, 27, 31, 9, 5, 26], [25, 4, 1, 19, 27, 31, 9, 5, 26, 33], [4, 1, 19, 27, 31, 9, 5, 26, 33, 26], [1, 19, 27, 31, 9, 5, 26, 33, 26, 5], [19, 27, 31, 9, 5, 26, 33, 26, 5, 35], [27, 31, 9, 5, 26, 33, 26, 5, 35, 14], [31, 9, 5, 26, 33, 26, 5, 35, 14, 27], [9, 5, 26, 33, 26, 5, 35, 14, 27, 26], [5, 26, 33, 26, 5, 35, 14, 27, 26, 24], [26, 33, 26, 5, 35, 14, 27, 26, 24, 5], [33, 26, 5, 35, 14, 27, 26, 24, 5, 9], [26, 5, 35, 14, 27, 26, 24, 5, 9, 1], [5, 35, 14, 27, 26, 24, 5, 9, 1, 2], [35, 14, 27, 26, 24, 5, 9, 1, 2, 6], [14, 27, 26, 24, 5, 9, 1, 2, 6, 28], [27, 26, 24, 5, 9, 1, 2, 6, 28, 34], [26, 24, 5, 9, 1, 2, 6, 28, 34, 1], [24, 5, 9, 1, 2, 6, 28, 34, 1, 15], [5, 9, 1, 2, 6, 28, 34, 1, 15, 3], [9, 1, 2, 6, 28, 34, 1, 15, 3, 26], [1, 2, 6, 28, 34, 1, 15, 3, 26, 26], [2, 6, 28, 34, 1, 15, 3, 26, 26, 5], [6, 28, 34, 1, 15, 3, 26, 26, 5, 25], [28, 34, 1, 15, 3, 26, 26, 5, 25, 35], [34, 1, 15, 3, 26, 26, 5, 25, 35, 1], [1, 15, 3, 26, 26, 5, 25, 35, 1, 0], [15, 3, 26, 26, 5, 25, 35, 1, 0, 14], [3, 26, 26, 5, 25, 35, 1, 0, 14, 13], [26, 26, 5, 25, 35, 1, 0, 14, 13, 3], [26, 5, 25, 35, 1, 0, 14, 13, 3, 26], [5, 25, 35, 1, 0, 14, 13, 3, 26, 9], [25, 35, 1, 0, 14, 13, 3, 26, 9, 1], [35, 1, 0, 14, 13, 3, 26, 9, 1, 3], [1, 0, 14, 13, 3, 26, 9, 1, 3, 1], [0, 14, 13, 3, 26, 9, 1, 3, 1, 29], [14, 13, 3, 26, 9, 1, 3, 1, 29, 17], [13, 3, 26, 9, 1, 3, 1, 29, 17, 35], [3, 26, 9, 1, 3, 1, 29, 17, 35, 24], [26, 9, 1, 3, 1, 29, 17, 35, 24, 3], [9, 1, 3, 1, 29, 17, 35, 24, 3, 25], [1, 3, 1, 29, 17, 35, 24, 3, 25, 1], [3, 1, 29, 17, 35, 24, 3, 25, 1, 24], [1, 29, 17, 35, 24, 3, 25, 1, 24, 25], [29, 17, 35, 24, 3, 25, 1, 24, 25, 17], [17, 35, 24, 3, 25, 1, 24, 25, 17, 29], [35, 24, 3, 25, 1, 24, 25, 17, 29, 29]]\n",
      "[[14, 26, 1, 0, 23, 5, 1, 21, 3], [26, 1, 0, 23, 5, 1, 21, 3, 35], [1, 0, 23, 5, 1, 21, 3, 35, 0], [0, 23, 5, 1, 21, 3, 35, 0, 1], [23, 5, 1, 21, 3, 35, 0, 1, 22], [5, 1, 21, 3, 35, 0, 1, 22, 22], [1, 21, 3, 35, 0, 1, 22, 22, 1], [21, 3, 35, 0, 1, 22, 22, 1, 4], [3, 35, 0, 1, 22, 22, 1, 4, 5], [35, 0, 1, 22, 22, 1, 4, 5, 3], [0, 1, 22, 22, 1, 4, 5, 3, 26], [1, 22, 22, 1, 4, 5, 3, 26, 35], [22, 22, 1, 4, 5, 3, 26, 35, 10], [22, 1, 4, 5, 3, 26, 35, 10, 1], [1, 4, 5, 3, 26, 35, 10, 1, 16], [4, 5, 3, 26, 35, 10, 1, 16, 0], [5, 3, 26, 35, 10, 1, 16, 0, 26], [3, 26, 35, 10, 1, 16, 0, 26, 3], [26, 35, 10, 1, 16, 0, 26, 3, 27], [35, 10, 1, 16, 0, 26, 3, 27, 35], [10, 1, 16, 0, 26, 3, 27, 35, 1], [1, 16, 0, 26, 3, 27, 35, 1, 23], [16, 0, 26, 3, 27, 35, 1, 23, 3], [0, 26, 3, 27, 35, 1, 23, 3, 35], [26, 3, 27, 35, 1, 23, 3, 35, 1], [3, 27, 35, 1, 23, 3, 35, 1, 15], [27, 35, 1, 23, 3, 35, 1, 15, 5], [35, 1, 23, 3, 35, 1, 15, 5, 5], [1, 23, 3, 35, 1, 15, 5, 5, 31], [23, 3, 35, 1, 15, 5, 5, 31, 1], [3, 35, 1, 15, 5, 5, 31, 1, 36], [35, 1, 15, 5, 5, 31, 1, 36, 14], [1, 15, 5, 5, 31, 1, 36, 14, 27], [15, 5, 5, 31, 1, 36, 14, 27, 35], [5, 5, 31, 1, 36, 14, 27, 35, 5], [5, 31, 1, 36, 14, 27, 35, 5, 1], [31, 1, 36, 14, 27, 35, 5, 1, 24], [1, 36, 14, 27, 35, 5, 1, 24, 23], [36, 14, 27, 35, 5, 1, 24, 23, 3], [14, 27, 35, 5, 1, 24, 23, 3, 17], [27, 35, 5, 1, 24, 23, 3, 17, 26], [35, 5, 1, 24, 23, 3, 17, 26, 1], [5, 1, 24, 23, 3, 17, 26, 1, 14], [1, 24, 23, 3, 17, 26, 1, 14, 29], [24, 23, 3, 17, 26, 1, 14, 29, 1], [23, 3, 17, 26, 1, 14, 29, 1, 0], [3, 17, 26, 1, 14, 29, 1, 0, 23], [17, 26, 1, 14, 29, 1, 0, 23, 5], [26, 1, 14, 29, 1, 0, 23, 5, 1], [1, 14, 29, 1, 0, 23, 5, 1, 32], [14, 29, 1, 0, 23, 5, 1, 32, 14], [29, 1, 0, 23, 5, 1, 32, 14, 17], [1, 0, 23, 5, 1, 32, 14, 17, 31], [0, 23, 5, 1, 32, 14, 17, 31, 0], [23, 5, 1, 32, 14, 17, 31, 0, 1], [5, 1, 32, 14, 17, 31, 0, 1, 28], [1, 32, 14, 17, 31, 0, 1, 28, 26], [32, 14, 17, 31, 0, 1, 28, 26, 3], [14, 17, 31, 0, 1, 28, 26, 3, 31], [17, 31, 0, 1, 28, 26, 3, 31, 35], [31, 0, 1, 28, 26, 3, 31, 35, 21], [0, 1, 28, 26, 3, 31, 35, 21, 14], [1, 28, 26, 3, 31, 35, 21, 14, 26], [28, 26, 3, 31, 35, 21, 14, 26, 0], [26, 3, 31, 35, 21, 14, 26, 0, 3], [3, 31, 35, 21, 14, 26, 0, 3, 0], [31, 35, 21, 14, 26, 0, 3, 0, 17], [35, 21, 14, 26, 0, 3, 0, 17, 14], [21, 14, 26, 0, 3, 0, 17, 14, 31], [14, 26, 0, 3, 0, 17, 14, 31, 1], [26, 0, 3, 0, 17, 14, 31, 1, 7], [0, 3, 0, 17, 14, 31, 1, 7, 14], [3, 0, 17, 14, 31, 1, 7, 14, 18], [0, 17, 14, 31, 1, 7, 14, 18, 18], [17, 14, 31, 1, 7, 14, 18, 18, 17], [14, 31, 1, 7, 14, 18, 18, 17, 0], [31, 1, 7, 14, 18, 18, 17, 0, 0], [1, 7, 14, 18, 18, 17, 0, 0, 5], [7, 14, 18, 18, 17, 0, 0, 5, 5], [14, 18, 18, 17, 0, 0, 5, 5, 12], [18, 18, 17, 0, 0, 5, 5, 12, 1], [18, 17, 0, 0, 5, 5, 12, 1, 19], [17, 0, 0, 5, 5, 12, 1, 19, 36], [0, 0, 5, 5, 12, 1, 19, 36, 5], [0, 5, 5, 12, 1, 19, 36, 5, 1], [5, 5, 12, 1, 19, 36, 5, 1, 3], [5, 12, 1, 19, 36, 5, 1, 3, 25], [12, 1, 19, 36, 5, 1, 3, 25, 35], [1, 19, 36, 5, 1, 3, 25, 35, 14], [19, 36, 5, 1, 3, 25, 35, 14, 1], [36, 5, 1, 3, 25, 35, 14, 1, 35], [5, 1, 3, 25, 35, 14, 1, 35, 17], [1, 3, 25, 35, 14, 1, 35, 17, 0], [3, 25, 35, 14, 1, 35, 17, 0, 35], [25, 35, 14, 1, 35, 17, 0, 35, 1], [35, 14, 1, 35, 17, 0, 35, 1, 14], [14, 1, 35, 17, 0, 35, 1, 14, 31], [1, 35, 17, 0, 35, 1, 14, 31, 1], [35, 17, 0, 35, 1, 14, 31, 1, 3], [17, 0, 35, 1, 14, 31, 1, 3, 1], [0, 35, 1, 14, 31, 1, 3, 1, 0], [35, 1, 14, 31, 1, 3, 1, 0, 26], [1, 14, 31, 1, 3, 1, 0, 26, 3], [14, 31, 1, 3, 1, 0, 26, 3, 31], [31, 1, 3, 1, 0, 26, 3, 31, 35], [1, 3, 1, 0, 26, 3, 31, 35, 21], [3, 1, 0, 26, 3, 31, 35, 21, 14], [1, 0, 26, 3, 31, 35, 21, 14, 26], [0, 26, 3, 31, 35, 21, 14, 26, 0], [26, 3, 31, 35, 21, 14, 26, 0, 3], [3, 31, 35, 21, 14, 26, 0, 3, 0], [31, 35, 21, 14, 26, 0, 3, 0, 17], [35, 21, 14, 26, 0, 3, 0, 17, 14], [21, 14, 26, 0, 3, 0, 17, 14, 31], [14, 26, 0, 3, 0, 17, 14, 31, 1], [26, 0, 3, 0, 17, 14, 31, 1, 29], [0, 3, 0, 17, 14, 31, 1, 29, 27], [3, 0, 17, 14, 31, 1, 29, 27, 31], [0, 17, 14, 31, 1, 29, 27, 31, 9], [17, 14, 31, 1, 29, 27, 31, 9, 17], [14, 31, 1, 29, 27, 31, 9, 17, 31], [31, 1, 29, 27, 31, 9, 17, 31, 20], [1, 29, 27, 31, 9, 17, 31, 20, 1], [29, 27, 31, 9, 17, 31, 20, 1, 0], [27, 31, 9, 17, 31, 20, 1, 0, 3], [31, 9, 17, 31, 20, 1, 0, 3, 35], [9, 17, 31, 20, 1, 0, 3, 35, 11], [17, 31, 20, 1, 0, 3, 35, 11, 1], [31, 20, 1, 0, 3, 35, 11, 1, 29], [20, 1, 0, 3, 35, 11, 1, 29, 14], [1, 0, 3, 35, 11, 1, 29, 14, 26], [0, 3, 35, 11, 1, 29, 14, 26, 24], [3, 35, 11, 1, 29, 14, 26, 24, 5], [35, 11, 1, 29, 14, 26, 24, 5, 1], [11, 1, 29, 14, 26, 24, 5, 1, 24], [1, 29, 14, 26, 24, 5, 1, 24, 23], [29, 14, 26, 24, 5, 1, 24, 23, 3], [14, 26, 24, 5, 1, 24, 23, 3, 26], [26, 24, 5, 1, 24, 23, 3, 26, 20], [24, 5, 1, 24, 23, 3, 26, 20, 5], [5, 1, 24, 23, 3, 26, 20, 5, 9], [1, 24, 23, 3, 26, 20, 5, 9, 1], [24, 23, 3, 26, 20, 5, 9, 1, 13], [23, 3, 26, 20, 5, 9, 1, 13, 17], [3, 26, 20, 5, 9, 1, 13, 17, 0], [26, 20, 5, 9, 1, 13, 17, 0, 23], [20, 5, 9, 1, 13, 17, 0, 23, 1], [5, 9, 1, 13, 17, 0, 23, 1, 24], [9, 1, 13, 17, 0, 23, 1, 24, 14], [1, 13, 17, 0, 23, 1, 24, 14, 31], [13, 17, 0, 23, 1, 24, 14, 31, 35], [17, 0, 23, 1, 24, 14, 31, 35, 17], [0, 23, 1, 24, 14, 31, 35, 17, 9], [23, 1, 24, 14, 31, 35, 17, 9, 5], [1, 24, 14, 31, 35, 17, 9, 5, 26], [24, 14, 31, 35, 17, 9, 5, 26, 17], [14, 31, 35, 17, 9, 5, 26, 17, 31], [31, 35, 17, 9, 5, 26, 17, 31, 20], [35, 17, 9, 5, 26, 17, 31, 20, 1], [17, 9, 5, 26, 17, 31, 20, 1, 19], [9, 5, 26, 17, 31, 20, 1, 19, 13], [5, 26, 17, 31, 20, 1, 19, 13, 23], [26, 17, 31, 20, 1, 19, 13, 23, 3], [17, 31, 20, 1, 19, 13, 23, 3, 0], [31, 20, 1, 19, 13, 23, 3, 0, 1], [20, 1, 19, 13, 23, 3, 0, 1, 0], [1, 19, 13, 23, 3, 0, 1, 0, 23], [19, 13, 23, 3, 0, 1, 0, 23, 5], [13, 23, 3, 0, 1, 0, 23, 5, 1], [23, 3, 0, 1, 0, 23, 5, 1, 31], [3, 0, 1, 0, 23, 5, 1, 31, 5], [0, 1, 0, 23, 5, 1, 31, 5, 8], [1, 0, 23, 5, 1, 31, 5, 8, 0], [0, 23, 5, 1, 31, 5, 8, 0, 1], [23, 5, 1, 31, 5, 8, 0, 1, 5], [5, 1, 31, 5, 8, 0, 1, 5, 26], [1, 31, 5, 8, 0, 1, 5, 26, 3], [31, 5, 8, 0, 1, 5, 26, 3, 1], [5, 8, 0, 1, 5, 26, 3, 1, 14], [8, 0, 1, 5, 26, 3, 1, 14, 29], [0, 1, 5, 26, 3, 1, 14, 29, 1], [1, 5, 26, 3, 1, 14, 29, 1, 0], [5, 26, 3, 1, 14, 29, 1, 0, 26], [26, 3, 1, 14, 29, 1, 0, 26, 3], [3, 1, 14, 29, 1, 0, 26, 3, 31], [1, 14, 29, 1, 0, 26, 3, 31, 35], [14, 29, 1, 0, 26, 3, 31, 35, 21], [29, 1, 0, 26, 3, 31, 35, 21, 14], [1, 0, 26, 3, 31, 35, 21, 14, 26], [0, 26, 3, 31, 35, 21, 14, 26, 0], [26, 3, 31, 35, 21, 14, 26, 0, 3], [3, 31, 35, 21, 14, 26, 0, 3, 0], [31, 35, 21, 14, 26, 0, 3, 0, 17], [35, 21, 14, 26, 0, 3, 0, 17, 14], [21, 14, 26, 0, 3, 0, 17, 14, 31], [14, 26, 0, 3, 0, 17, 14, 31, 1], [26, 0, 3, 0, 17, 14, 31, 1, 29], [0, 3, 0, 17, 14, 31, 1, 29, 27], [3, 0, 17, 14, 31, 1, 29, 27, 31], [0, 17, 14, 31, 1, 29, 27, 31, 9], [17, 14, 31, 1, 29, 27, 31, 9, 17], [14, 31, 1, 29, 27, 31, 9, 17, 31], [31, 1, 29, 27, 31, 9, 17, 31, 20], [1, 29, 27, 31, 9, 17, 31, 20, 1], [29, 27, 31, 9, 17, 31, 20, 1, 24], [27, 31, 9, 17, 31, 20, 1, 24, 14], [31, 9, 17, 31, 20, 1, 24, 14, 27], [9, 17, 31, 20, 1, 24, 14, 27, 25], [17, 31, 20, 1, 24, 14, 27, 25, 9], [31, 20, 1, 24, 14, 27, 25, 9, 1], [20, 1, 24, 14, 27, 25, 9, 1, 25], [1, 24, 14, 27, 25, 9, 1, 25, 14], [24, 14, 27, 25, 9, 1, 25, 14, 14], [14, 27, 25, 9, 1, 25, 14, 14, 11], [27, 25, 9, 1, 25, 14, 14, 11, 1], [25, 9, 1, 25, 14, 14, 11, 1, 25], [9, 1, 25, 14, 14, 11, 1, 25, 17], [1, 25, 14, 14, 11, 1, 25, 17, 11], [25, 14, 14, 11, 1, 25, 17, 11, 5], [14, 14, 11, 1, 25, 17, 11, 5, 1], [14, 11, 1, 25, 17, 11, 5, 1, 3], [11, 1, 25, 17, 11, 5, 1, 3, 35], [1, 25, 17, 11, 5, 1, 3, 35, 1], [25, 17, 11, 5, 1, 3, 35, 1, 0], [17, 11, 5, 1, 3, 35, 1, 0, 23], [11, 5, 1, 3, 35, 1, 0, 23, 5], [5, 1, 3, 35, 1, 0, 23, 5, 1], [1, 3, 35, 1, 0, 23, 5, 1, 31], [3, 35, 1, 0, 23, 5, 1, 31, 14], [35, 1, 0, 23, 5, 1, 31, 14, 0], [1, 0, 23, 5, 1, 31, 14, 0, 14], [0, 23, 5, 1, 31, 14, 0, 14, 26], [23, 5, 1, 31, 14, 0, 14, 26, 17], [5, 1, 31, 14, 0, 14, 26, 17, 14], [1, 31, 14, 0, 14, 26, 17, 14, 27], [31, 14, 0, 14, 26, 17, 14, 27, 35], [14, 0, 14, 26, 17, 14, 27, 35, 25], [0, 14, 26, 17, 14, 27, 35, 25, 4], [14, 26, 17, 14, 27, 35, 25, 4, 1], [26, 17, 14, 27, 35, 25, 4, 1, 19], [17, 14, 27, 35, 25, 4, 1, 19, 27], [14, 27, 35, 25, 4, 1, 19, 27, 31], [27, 35, 25, 4, 1, 19, 27, 31, 9], [35, 25, 4, 1, 19, 27, 31, 9, 5], [25, 4, 1, 19, 27, 31, 9, 5, 26], [4, 1, 19, 27, 31, 9, 5, 26, 33], [1, 19, 27, 31, 9, 5, 26, 33, 26], [19, 27, 31, 9, 5, 26, 33, 26, 5], [27, 31, 9, 5, 26, 33, 26, 5, 35], [31, 9, 5, 26, 33, 26, 5, 35, 14], [9, 5, 26, 33, 26, 5, 35, 14, 27], [5, 26, 33, 26, 5, 35, 14, 27, 26], [26, 33, 26, 5, 35, 14, 27, 26, 24], [33, 26, 5, 35, 14, 27, 26, 24, 5], [26, 5, 35, 14, 27, 26, 24, 5, 9], [5, 35, 14, 27, 26, 24, 5, 9, 1], [35, 14, 27, 26, 24, 5, 9, 1, 2], [14, 27, 26, 24, 5, 9, 1, 2, 6], [27, 26, 24, 5, 9, 1, 2, 6, 28], [26, 24, 5, 9, 1, 2, 6, 28, 34], [24, 5, 9, 1, 2, 6, 28, 34, 1], [5, 9, 1, 2, 6, 28, 34, 1, 15], [9, 1, 2, 6, 28, 34, 1, 15, 3], [1, 2, 6, 28, 34, 1, 15, 3, 26], [2, 6, 28, 34, 1, 15, 3, 26, 26], [6, 28, 34, 1, 15, 3, 26, 26, 5], [28, 34, 1, 15, 3, 26, 26, 5, 25], [34, 1, 15, 3, 26, 26, 5, 25, 35], [1, 15, 3, 26, 26, 5, 25, 35, 1], [15, 3, 26, 26, 5, 25, 35, 1, 0], [3, 26, 26, 5, 25, 35, 1, 0, 14], [26, 26, 5, 25, 35, 1, 0, 14, 13], [26, 5, 25, 35, 1, 0, 14, 13, 3], [5, 25, 35, 1, 0, 14, 13, 3, 26], [25, 35, 1, 0, 14, 13, 3, 26, 9], [35, 1, 0, 14, 13, 3, 26, 9, 1], [1, 0, 14, 13, 3, 26, 9, 1, 3], [0, 14, 13, 3, 26, 9, 1, 3, 1], [14, 13, 3, 26, 9, 1, 3, 1, 29], [13, 3, 26, 9, 1, 3, 1, 29, 17], [3, 26, 9, 1, 3, 1, 29, 17, 35], [26, 9, 1, 3, 1, 29, 17, 35, 24], [9, 1, 3, 1, 29, 17, 35, 24, 3], [1, 3, 1, 29, 17, 35, 24, 3, 25], [3, 1, 29, 17, 35, 24, 3, 25, 1], [1, 29, 17, 35, 24, 3, 25, 1, 24], [29, 17, 35, 24, 3, 25, 1, 24, 25], [17, 35, 24, 3, 25, 1, 24, 25, 17], [35, 24, 3, 25, 1, 24, 25, 17, 29], [24, 3, 25, 1, 24, 25, 17, 29, 29]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "tensor([[14, 26,  1,  ...,  1, 21,  3],\n",
      "        [26,  1,  0,  ..., 21,  3, 35],\n",
      "        [ 1,  0, 23,  ...,  3, 35,  0],\n",
      "        ...,\n",
      "        [17, 35, 24,  ..., 24, 25, 17],\n",
      "        [35, 24,  3,  ..., 25, 17, 29],\n",
      "        [24,  3, 25,  ..., 17, 29, 29]])\n"
     ]
    }
   ],
   "source": [
    "#원-핫 인코딩\n",
    "x_one_hot2=[np.eye(char_dic_size)[x] for x in x_data]\n",
    "X=torch.FloatTensor(x_one_hot2)\n",
    "Y=torch.LongTensor(y_data)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 26,  1,  ...,  1, 21,  3],\n",
      "        [26,  1,  0,  ..., 21,  3, 35],\n",
      "        [ 1,  0, 23,  ...,  3, 35,  0],\n",
      "        ...,\n",
      "        [17, 35, 24,  ..., 24, 25, 17],\n",
      "        [35, 24,  3,  ..., 25, 17, 29],\n",
      "        [24,  3, 25,  ..., 17, 29, 29]])\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([290, 10, 37]) torch.Size([290, 9])\n"
     ]
    }
   ],
   "source": [
    "print(X.size(),Y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self,input_dim,hidden_dim,layers):\n",
    "    super(Net, self).__init__()\n",
    "    self.rnn=nn.RNN(input_dim,hidden_dim,num_layers=layers,\n",
    "                    batch_first=True)\n",
    "    self.fc=nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x,_status=self.rnn(x)\n",
    "    x=self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net(char_dic_size,hidden_size,2)\n",
    " #층을 2개 쌓는다는 의미\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([290, 10, 37])\n"
     ]
    }
   ],
   "source": [
    "outputs=model(X)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2900, 37])\n"
     ]
    }
   ],
   "source": [
    "result=outputs.view(-1,char_dic_size)\n",
    "print(result.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련\n",
    "for i in range(200):\n",
    "  optimizer.zero_grad()\n",
    "  outputs=model(X)\n",
    "  loss=criterion(outputs.view(-1,char_dic_size),Y.view(-1))\n",
    "\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  results=outputs.argmax(dim=2)\n",
    "  predict_str=\"\"\n",
    "\n",
    "  for j,result in enumerate(results):\n",
    "    if j==0 :\n",
    "      predict_str+=''.join([char_set2[t] for t in result])\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.8 ('pytorchtest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e473da0440022a3b9533296b86af0c6bf3963b38d184c0e31ca2ce5e4d2e295"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
